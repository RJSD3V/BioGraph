{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97b68c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0aa3f6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raajassode/dev/genai/biograph/venv/lib/python3.13/site-packages/IPython/core/interactiveshell.py:3670: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from typing import Any, Optional , List\n",
    "from typing_extensions import TypedDict\n",
    "import os, json, logging\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "#Langgraph and Langchain dependencies. \n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "#from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain.tools import BaseTool, StructuredTool, tool\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables.graph_mermaid import draw_mermaid_png\n",
    "\n",
    "#Manage Environment Variables. \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "auradb_conn=os.environ[\"AURADB_CONN\"]\n",
    "auradb_username = os.environ[\"AURADB_USERNAME\"]\n",
    "auradb_password = os.environ[\"AURADB_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b3e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os , getpass\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def _set_env(var:  str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b98443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    text:str\n",
    "    nodes: Optional[List[dict]]\n",
    "    is_graph_pushed: Optional[bool]\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136cf058",
   "metadata": {},
   "source": [
    "# Building the Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67c65470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tool(\"push_graph\")\n",
    "def push_graph(state:State) -> Any:\n",
    "\n",
    "    \"\"\" Push the json object with nodes and relationsips between entities to an AuraDB Graph database instance\n",
    "\n",
    "    Args:\n",
    "         state : State -> state object that holds the json property from the State that \n",
    "                            is essentially a list of  json objects or Python list of dicts that \n",
    "                            has the graph data with nodes and relationships.\n",
    "\n",
    "    Returns:\n",
    "          dict : Updates the state object by returning if the graph push was successful\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    AURA_CONNECTION_URI = auradb_conn\n",
    "    AURA_USERNAME = \"neo4j\"\n",
    "    AURA_PASSWORD = auradb_password\n",
    "\n",
    "    # Driver instantiation\n",
    "    driver = GraphDatabase.driver(\n",
    "        AURA_CONNECTION_URI,\n",
    "        auth=(AURA_USERNAME, AURA_PASSWORD)\n",
    "    )\n",
    "\n",
    "    import uuid\n",
    "\n",
    "    input_data = state[\"nodes\"] # Your provided JSON here\n",
    "    \n",
    "    # Transform nodes\n",
    "    nodes = {item[\"node\"]: {\"id\": str(uuid.uuid4())} for item in input_data}\n",
    "\n",
    "    # Transform relationships\n",
    "    relationships = []\n",
    "    for item in input_data:\n",
    "        source_node = item[\"node\"]\n",
    "        for rel in item[\"relationships\"]:\n",
    "            relationships.append({\n",
    "                \"source\": source_node,\n",
    "                \"target\": rel.get(\"target\", rel.get(\"source\")),\n",
    "                \"type\": rel[\"type\"].upper().replace(\" \", \"_\")\n",
    "            })\n",
    "\n",
    "\n",
    "    def create_graph(tx):\n",
    "        # Create nodes with unique IDs\n",
    "        for name, props in nodes.items():\n",
    "            nodes_result = tx.run(\"\"\"\n",
    "                MERGE (n:Species {name: $name})\n",
    "                SET n.id = $id\n",
    "            \"\"\", name=name, id=props[\"id\"])\n",
    "\n",
    "        # Create relationships\n",
    "        for rel in relationships:\n",
    "            relationships_result = tx.run(\"\"\"\n",
    "                MATCH (a:Species {name: $source}), (b:Species {name: $target})\n",
    "                MERGE (a)-[r:RELATES_TO {type: $type}]->(b)\n",
    "            \"\"\", source=rel[\"source\"], target=rel[\"target\"], type=rel[\"type\"])\n",
    "    \n",
    "        return {\"nodes\": nodes_result.consume(), \"relationships\": relationships_result.consume()}\n",
    "\n",
    "    \n",
    "    try:\n",
    "        with driver.session() as session:\n",
    "            summary = session.execute_write(create_graph)\n",
    "        \n",
    "            \n",
    "            return{\"messages\":{\"role\":\"assistant\",\"content\":f\"Graph push successful with {summary['nodes'].counters} nodes and {summary['relationships'].counters}\"}\n",
    "                   , \"is_graph_pushed\": True\n",
    "                   }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return{\"messages\":[{\"role\":\"assistant\",\"content\":f\"Graph push failed with error: {str(e)}\"\n",
    "            }],\n",
    "            \"is_graph_pushed\": False\n",
    "            }\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07d54d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(\"process_passage\")\n",
    "def process_passage(state:State):\n",
    "    \n",
    "    \"\"\" \n",
    "     Identifies node and relationships between entities in the input text passage. \n",
    "     The objective of the function is to return a json object or Python dictionary, which will be passed\n",
    "     to the push_graph function that stores it in the auradb graph databse. \n",
    "\n",
    "     args:\n",
    "        text: str -> State object which has the text property to be used to parse nodes and relationships from. \n",
    "      \n",
    "     returns:\n",
    "        dict: python dictionary that outlines nodes and relationships between entities in the given passage\n",
    "     \n",
    "    \n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(\"\"\"For the following passage, give me ONLY a serialized json object that \n",
    "    describes the relationship between the species, compatible with a graph data structure. \n",
    "    For example a graph relationship: Lion --> (predator) --> Antelope should output a serialized json string \\n\n",
    "\n",
    "    the passage starts from the next line \\n {text} \\n\n",
    "\n",
    "\n",
    "    *** Requirements ***\n",
    "\n",
    "        - Only return the json object. Nothing else.\n",
    "        - each node relationship should have only one source or target. Not a list. \n",
    "        - Add any node and relationship properties (ecosystem, etc.) based on the passage\n",
    "\n",
    "    *** Example output for a relationship ***\n",
    "\n",
    "    {{\n",
    "       \"node\": \"Jaguar\",\n",
    "       \"relationships\": [\n",
    "         {{\n",
    "           \"type\": \"predator\",\n",
    "           \"target\": \"Capybara\"\n",
    "         }}\n",
    "       ]\n",
    "     }}\n",
    "\n",
    "    \"\"\")\n",
    "    \n",
    "    parser_llm = ChatOllama(model=\"mistral:instruct\")\n",
    "    formatted_prompt = prompt.format(text=state[\"text\"])\n",
    "    response = parser_llm.invoke(formatted_prompt)\n",
    "    parser = JsonOutputParser()\n",
    "    return {\"messages\":[{\"role\":\"assistant\",\"content\":f\"Graph Created Successfully\", \"body\": parser.parse(response.content)}],\"json\": parser.parse(response.content)}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7faeca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "config:\n",
      "  flowchart:\n",
      "    curve: linear\n",
      "---\n",
      "graph TD;\n",
      "\t__start__([<p>__start__</p>]):::first\n",
      "\tprocess_passage(process_passage)\n",
      "\tpush_graph(push_graph)\n",
      "\t__end__([<p>__end__</p>]):::last\n",
      "\t__start__ --> process_passage;\n",
      "\tprocess_passage --> push_graph;\n",
      "\tpush_graph --> __end__;\n",
      "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
      "\tclassDef first fill-opacity:0\n",
      "\tclassDef last fill:#bfb6fc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"process_passage\", process_passage)\n",
    "builder.add_node(\"push_graph\",push_graph)\n",
    "builder.add_edge(START, \"process_passage\")\n",
    "builder.add_edge(\"process_passage\",\"push_graph\")\n",
    "builder.add_edge(\"push_graph\", END)\n",
    "\n",
    "\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "mermaid_code = graph.get_graph().draw_mermaid()\n",
    "print(mermaid_code)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c298c580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg id=\"mermaid-svg\" width=\"100%\" xmlns=\"http://www.w3.org/2000/svg\" class=\"flowchart\" style=\"max-width: 171.421875px;\" viewBox=\"0 0 171.421875 332.75\" role=\"graphics-document document\" aria-roledescription=\"flowchart-v2\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><style xmlns=\"http://www.w3.org/1999/xhtml\">@import url(\"https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.7.2/css/all.min.css\");</style><style>#mermaid-svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;fill:#333;}@keyframes edge-animation-frame{from{stroke-dashoffset:0;}}@keyframes dash{to{stroke-dashoffset:0;}}#mermaid-svg .edge-animation-slow{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 50s linear infinite;stroke-linecap:round;}#mermaid-svg .edge-animation-fast{stroke-dasharray:9,5!important;stroke-dashoffset:900;animation:dash 20s linear infinite;stroke-linecap:round;}#mermaid-svg .error-icon{fill:#552222;}#mermaid-svg .error-text{fill:#552222;stroke:#552222;}#mermaid-svg .edge-thickness-normal{stroke-width:1px;}#mermaid-svg .edge-thickness-thick{stroke-width:3.5px;}#mermaid-svg .edge-pattern-solid{stroke-dasharray:0;}#mermaid-svg .edge-thickness-invisible{stroke-width:0;fill:none;}#mermaid-svg .edge-pattern-dashed{stroke-dasharray:3;}#mermaid-svg .edge-pattern-dotted{stroke-dasharray:2;}#mermaid-svg .marker{fill:#333333;stroke:#333333;}#mermaid-svg .marker.cross{stroke:#333333;}#mermaid-svg svg{font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:16px;}#mermaid-svg p{margin:0;}#mermaid-svg .label{font-family:\"trebuchet ms\",verdana,arial,sans-serif;color:#333;}#mermaid-svg .cluster-label text{fill:#333;}#mermaid-svg .cluster-label span{color:#333;}#mermaid-svg .cluster-label span p{background-color:transparent;}#mermaid-svg .label text,#mermaid-svg span{fill:#333;color:#333;}#mermaid-svg .node rect,#mermaid-svg .node circle,#mermaid-svg .node ellipse,#mermaid-svg .node polygon,#mermaid-svg .node path{fill:#ECECFF;stroke:#9370DB;stroke-width:1px;}#mermaid-svg .rough-node .label text,#mermaid-svg .node .label text,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-anchor:middle;}#mermaid-svg .node .katex path{fill:#000;stroke:#000;stroke-width:1px;}#mermaid-svg .rough-node .label,#mermaid-svg .node .label,#mermaid-svg .image-shape .label,#mermaid-svg .icon-shape .label{text-align:center;}#mermaid-svg .node.clickable{cursor:pointer;}#mermaid-svg .root .anchor path{fill:#333333!important;stroke-width:0;stroke:#333333;}#mermaid-svg .arrowheadPath{fill:#333333;}#mermaid-svg .edgePath .path{stroke:#333333;stroke-width:2.0px;}#mermaid-svg .flowchart-link{stroke:#333333;fill:none;}#mermaid-svg .edgeLabel{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .edgeLabel p{background-color:rgba(232,232,232, 0.8);}#mermaid-svg .edgeLabel rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg .labelBkg{background-color:rgba(232, 232, 232, 0.5);}#mermaid-svg .cluster rect{fill:#ffffde;stroke:#aaaa33;stroke-width:1px;}#mermaid-svg .cluster text{fill:#333;}#mermaid-svg .cluster span{color:#333;}#mermaid-svg div.mermaidTooltip{position:absolute;text-align:center;max-width:200px;padding:2px;font-family:\"trebuchet ms\",verdana,arial,sans-serif;font-size:12px;background:hsl(80, 100%, 96.2745098039%);border:1px solid #aaaa33;border-radius:2px;pointer-events:none;z-index:100;}#mermaid-svg .flowchartTitleText{text-anchor:middle;font-size:18px;fill:#333;}#mermaid-svg rect.text{fill:none;stroke-width:0;}#mermaid-svg .icon-shape,#mermaid-svg .image-shape{background-color:rgba(232,232,232, 0.8);text-align:center;}#mermaid-svg .icon-shape p,#mermaid-svg .image-shape p{background-color:rgba(232,232,232, 0.8);padding:2px;}#mermaid-svg .icon-shape rect,#mermaid-svg .image-shape rect{opacity:0.5;background-color:rgba(232,232,232, 0.8);fill:rgba(232,232,232, 0.8);}#mermaid-svg :root{--mermaid-font-family:\"trebuchet ms\",verdana,arial,sans-serif;}#mermaid-svg .default&gt;*{fill:#f2f0ff!important;line-height:1.2!important;}#mermaid-svg .default span{fill:#f2f0ff!important;line-height:1.2!important;}#mermaid-svg .first&gt;*{fill-opacity:0!important;}#mermaid-svg .first span{fill-opacity:0!important;}#mermaid-svg .last&gt;*{fill:#bfb6fc!important;}#mermaid-svg .last span{fill:#bfb6fc!important;}</style><g><marker id=\"mermaid-svg_flowchart-v2-pointEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 0 L 10 5 L 0 10 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-pointStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"4.5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"8\" markerHeight=\"8\" orient=\"auto\"><path d=\"M 0 5 L 10 10 L 10 0 z\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleEnd\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"11\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-circleStart\" class=\"marker flowchart-v2\" viewBox=\"0 0 10 10\" refX=\"-1\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><circle cx=\"5\" cy=\"5\" r=\"5\" class=\"arrowMarkerPath\" style=\"stroke-width: 1; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossEnd\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"12\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><marker id=\"mermaid-svg_flowchart-v2-crossStart\" class=\"marker cross flowchart-v2\" viewBox=\"0 0 11 11\" refX=\"-1\" refY=\"5.2\" markerUnits=\"userSpaceOnUse\" markerWidth=\"11\" markerHeight=\"11\" orient=\"auto\"><path d=\"M 1,1 l 9,9 M 10,1 l -9,9\" class=\"arrowMarkerPath\" style=\"stroke-width: 2; stroke-dasharray: 1, 0;\"/></marker><g class=\"root\"><g class=\"clusters\"/><g class=\"edgePaths\"><path d=\"M85.711,42.188L85.711,67.188L85.711,88.188\" id=\"L___start___process_passage_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M85.711,141.375L85.711,166.375L85.711,187.375\" id=\"L_process_passage_push_graph_0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/><path d=\"M85.711,240.563L85.711,265.563L85.711,286.563\" id=\"L_push_graph___end___0\" class=\" edge-thickness-normal edge-pattern-solid edge-thickness-normal edge-pattern-solid flowchart-link\" style=\"\" marker-end=\"url(#mermaid-svg_flowchart-v2-pointEnd)\"/></g><g class=\"edgeLabels\"><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g><g class=\"edgeLabel\"><g class=\"label\" transform=\"translate(0, 0)\"><foreignObject width=\"0\" height=\"0\"><div xmlns=\"http://www.w3.org/1999/xhtml\" class=\"labelBkg\" style=\"display: table-cell; white-space: nowrap; line-height: 1.5; max-width: 200px; text-align: center;\"><span class=\"edgeLabel \"></span></div></foreignObject></g></g></g><g class=\"nodes\"><g class=\"node default first \" id=\"flowchart-__start__-0\" transform=\"translate(85.7109375, 25.09375)\"><rect class=\"basic label-container\" style=\"fill:#f2f0ff !important;fill-opacity:0 !important\" rx=\"17.09375\" ry=\"17.09375\" x=\"-45.1328125\" y=\"-17.09375\" width=\"90.265625\" height=\"34.1875\"/><g class=\"label\" style=\"line-height:1.2 !important\" transform=\"translate(-33.359375, -9.59375)\"><rect/><foreignObject width=\"66.71875\" height=\"19.1875\"><div style=\"line-height: 1.5; display: table-cell; white-space: nowrap; max-width: 200px; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span style=\"line-height:1.2 !important\" class=\"nodeLabel \"><p>__start__</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-process_passage-1\" transform=\"translate(85.7109375, 116.78125)\"><rect class=\"basic label-container\" style=\"fill:#f2f0ff !important\" rx=\"5\" ry=\"5\" x=\"-77.7109375\" y=\"-24.59375\" width=\"155.421875\" height=\"49.1875\"/><g class=\"label\" style=\"line-height:1.2 !important\" transform=\"translate(-62.7109375, -9.59375)\"><rect/><foreignObject width=\"125.421875\" height=\"19.1875\"><div style=\"line-height: 1.5; display: table-cell; white-space: nowrap; max-width: 200px; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span style=\"line-height:1.2 !important\" class=\"nodeLabel \"><p>process_passage</p></span></div></foreignObject></g></g><g class=\"node default  \" id=\"flowchart-push_graph-2\" transform=\"translate(85.7109375, 215.96875)\"><rect class=\"basic label-container\" style=\"fill:#f2f0ff !important\" rx=\"5\" ry=\"5\" x=\"-57.2578125\" y=\"-24.59375\" width=\"114.515625\" height=\"49.1875\"/><g class=\"label\" style=\"line-height:1.2 !important\" transform=\"translate(-42.2578125, -9.59375)\"><rect/><foreignObject width=\"84.515625\" height=\"19.1875\"><div style=\"line-height: 1.5; display: table-cell; white-space: nowrap; max-width: 200px; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span style=\"line-height:1.2 !important\" class=\"nodeLabel \"><p>push_graph</p></span></div></foreignObject></g></g><g class=\"node default last \" id=\"flowchart-__end__-3\" transform=\"translate(85.7109375, 307.65625)\"><rect class=\"basic label-container\" style=\"fill:#bfb6fc !important\" rx=\"17.09375\" ry=\"17.09375\" x=\"-42.921875\" y=\"-17.09375\" width=\"85.84375\" height=\"34.1875\"/><g class=\"label\" style=\"line-height:1.2 !important\" transform=\"translate(-31.1484375, -9.59375)\"><rect/><foreignObject width=\"62.296875\" height=\"19.1875\"><div style=\"line-height: 1.5; display: table-cell; white-space: nowrap; max-width: 200px; text-align: center;\" xmlns=\"http://www.w3.org/1999/xhtml\"><span style=\"line-height:1.2 !important\" class=\"nodeLabel \"><p>__end__</p></span></div></foreignObject></g></g></g></g></g></svg>"
      ],
      "text/plain": [
       "<mermaid.__main__.Mermaid at 0x120dcc6e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mermaid as md \n",
    "from mermaid.graph import Graph \n",
    "\n",
    "render = md.Mermaid(mermaid_code)\n",
    "\n",
    "render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d704e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "passage = \"\"\"\n",
    "In the tropical rainforest ecosystem, several species exhibit a variety of biological relationships that illustrate evolutionary, ecological, and taxonomic connections. The Jaguar (Panthera onca) is a top predator and preys upon the Capybara (Hydrochoerus hydrochaeris) and the Green Anaconda (Eunectes murinus). Both the Capybara and Green Anaconda share the same wetland habitat, demonstrating ecological co-occurrence.\n",
    "The Green Anaconda often competes with the Harpy Eagle (Harpia harpyja) for prey such as the Howler Monkey (Alouatta palliata). The Howler Monkey, an arboreal primate, is closely related to the Spider Monkey (Ateles geoffroyi), with both belonging to the family Atelidae. This taxonomic relationship indicates a common evolutionary ancestor.\n",
    "The Harpy Eagle also preys on the Sloth (Bradypus variegatus), which has a mutualistic relationship with several species of algae, such as Trentepohlia spp., that grow on its fur, providing camouflage. Additionally, the Sloth shares a symbiotic relationship with the Moth (Cryptoses choloepi), which uses the slothâ€™s fur for habitat.\n",
    "From an evolutionary standpoint, the Capybara and the Jaguar belong to different orders: Rodentia and Carnivora, respectively, reflecting deep phylogenetic divergence. The Sloth is taxonomically grouped within the order Pilosa, distinct from the other mammals mentioned.\n",
    "Together, these species form a complex web of predation, competition, symbiosis, and shared evolutionary history, making the tropical rainforest a dynamic and interconnected ecosystem.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c488cfd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for process_passage\nstate\n  Field required [type=missing, input_value={'text': '\\nIn the tropic...tem.\\n', 'messages': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpprint\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pprint\n\u001b[32m      2\u001b[39m messages = []\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mgraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43mpassage\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m pprint(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2823\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2820\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2821\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2823\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2824\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2826\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2827\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2828\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2829\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2832\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2833\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2834\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2835\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2836\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2837\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2838\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langgraph/pregel/__init__.py:2461\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2455\u001b[39m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   2456\u001b[39m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[32m   2457\u001b[39m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   2458\u001b[39m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   2459\u001b[39m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[32m   2460\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m2461\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2462\u001b[39m \u001b[43m            \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2463\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2464\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2465\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2466\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2467\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2468\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2469\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:513\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    506\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    507\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    510\u001b[39m     **kwargs: Any,\n\u001b[32m    511\u001b[39m ) -> Any:\n\u001b[32m    512\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:774\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    773\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m774\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    775\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    776\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:736\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    734\u001b[39m child_config = patch_config(config, callbacks=run_manager.get_child())\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     tool_args, tool_kwargs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_to_args_and_kwargs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\n\u001b[32m    738\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    739\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m signature(\u001b[38;5;28mself\u001b[39m._run).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    740\u001b[39m         tool_kwargs = tool_kwargs | {\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m: run_manager}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:651\u001b[39m, in \u001b[36mBaseTool._to_args_and_kwargs\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    644\u001b[39m     \u001b[38;5;28mself\u001b[39m.args_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    645\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.args_schema, \u001b[38;5;28mtype\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m    648\u001b[39m ):\n\u001b[32m    649\u001b[39m     \u001b[38;5;66;03m# StructuredTool with no args\u001b[39;00m\n\u001b[32m    650\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (), {}\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m tool_input = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_parse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_call_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[38;5;66;03m# For backwards compatibility, if run_input is a string,\u001b[39;00m\n\u001b[32m    653\u001b[39m \u001b[38;5;66;03m# pass as a positional argument.\u001b[39;00m\n\u001b[32m    654\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool_input, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/langchain_core/tools/base.py:570\u001b[39m, in \u001b[36mBaseTool._parse_input\u001b[39m\u001b[34m(self, tool_input, tool_call_id)\u001b[39m\n\u001b[32m    568\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    569\u001b[39m             tool_input[k] = tool_call_id\n\u001b[32m--> \u001b[39m\u001b[32m570\u001b[39m     result = \u001b[43minput_args\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    571\u001b[39m     result_dict = result.model_dump()\n\u001b[32m    572\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(input_args, BaseModelV1):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dev/genai/biograph/venv/lib/python3.13/site-packages/pydantic/main.py:703\u001b[39m, in \u001b[36mBaseModel.model_validate\u001b[39m\u001b[34m(cls, obj, strict, from_attributes, context, by_alias, by_name)\u001b[39m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m by_alias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m by_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    698\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    699\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    700\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    701\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for process_passage\nstate\n  Field required [type=missing, input_value={'text': '\\nIn the tropic...tem.\\n', 'messages': []}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.11/v/missing",
      "During task with name 'process_passage' and id '669bfe03-12e3-7362-5e95-9b25cf5d01ac'"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "messages = []\n",
    "result = graph.invoke({\"messages\":messages, \"text\":passage})\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93109f9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
